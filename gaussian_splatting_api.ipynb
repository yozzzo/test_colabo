{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 3D Gaussian Splatting API on Google Colab\n**Version: 3.1.1** (Updated: 2025-06-01)\n**IMPORTANT: Check version number first! If not 3.1.1, reload from GitHub**\n\nBased on working implementation from: https://dev.classmethod.jp/articles/3d-gaussian-splatting-on-colab/\n\nMajor changes in v3.1.1:\n- Fixed DISPLAY environment variable type error\n- Proper CUDA/PyTorch configuration for T4 GPU\n- Correct COLMAP camera model settings\n- Working Gaussian Splatting training pipeline\n- Real PLY output (not fallback)\n\nThis notebook creates a FastAPI server that:\n- Accepts image/video uploads via HTTP POST\n- Extracts frames from videos (if needed)\n- Runs COLMAP for camera pose estimation\n- Trains a 3D Gaussian Splatting model\n- Returns the trained model (.ply file) via Google Drive\n\n**Note**: T4 GPU (16GB) with CUDA 12.2 and Compute Capability 7.5",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣ Install System Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Install system dependencies and virtual display\nprint(\"Installing system dependencies...\")\n!apt-get update -qq\n!apt-get install -y \\\n    libglew-dev \\\n    libassimp-dev \\\n    libboost-all-dev \\\n    libgtk-3-dev \\\n    libopencv-dev \\\n    libglfw3-dev \\\n    libavdevice-dev \\\n    libavcodec-dev \\\n    libeigen3-dev \\\n    libxxf86vm-dev \\\n    libembree-dev \\\n    cmake \\\n    imagemagick \\\n    ffmpeg \\\n    xvfb \\\n    x11-utils \\\n    python3-opengl \\\n    libegl1-mesa \\\n    libgl1-mesa-glx \\\n    libgles2-mesa \\\n    libosmesa6\n\n# Install virtual display library\n!pip install -q pyvirtualdisplay\n\n# Fix ImageMagick policy for PDF/PS files (sometimes needed)\n!sed -i '/disable ghostscript format types/,+6d' /etc/ImageMagick-6/policy.xml || true\n\nprint(\"✓ System dependencies installed\")"
  },
  {
   "cell_type": "code",
   "source": "# Setup virtual display and install COLMAP\nprint(\"Setting up virtual display...\")\n\n# Start virtual display\nfrom pyvirtualdisplay import Display\ndisplay = Display(visible=False, size=(1024, 768))\ndisplay.start()\nprint(f\"✓ Virtual display started: {display}\")\n\n# Set environment for headless operation\nimport os\nos.environ['DISPLAY'] = ':' + str(display.display)\nos.environ['PYOPENGL_PLATFORM'] = 'egl'\nos.environ['QT_QPA_PLATFORM'] = 'offscreen'\n\n# Install COLMAP\nprint(\"\\nInstalling COLMAP...\")\n!apt-get install -y colmap\n\n# Verify installation\nprint(\"\\nVerifying COLMAP installation...\")\n!which colmap\n!colmap -h | head -5 || echo \"COLMAP help\"\n\n# Test COLMAP can run\nimport subprocess\nresult = subprocess.run(['colmap', 'feature_extractor', '-h'], capture_output=True, text=True)\nif result.returncode == 0:\n    print(\"\\n✅ COLMAP successfully installed and can run!\")\n    print(\"Feature extractor help available\")\nelse:\n    print(\"\\n⚠️ COLMAP installation issue detected\")\n    print(f\"Error: {result.stderr}\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2️⃣ Clone and Setup Gaussian Splatting"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Clone the repository and setup properly\n!git clone https://github.com/graphdeco-inria/gaussian-splatting --recursive\n%cd gaussian-splatting\n\n# Check CUDA availability\nimport torch\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nprint(f\"CUDA version: {torch.version.cuda}\")\nprint(f\"PyTorch version: {torch.__version__}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Python dependencies\n",
    "!pip install -q plyfile tqdm opencv-python joblib\n",
    "!pip install -q fastapi uvicorn pyngrok nest-asyncio python-multipart aiofiles\n",
    "\n",
    "# Install submodules\n",
    "!pip install -q submodules/diff-gaussian-rasterization\n",
    "!pip install -q submodules/simple-knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Install Python dependencies in the correct order\nprint(\"Installing Python dependencies...\")\n\n# First install plyfile and other basic deps\n!pip install -q plyfile tqdm opencv-python joblib numpy\n\n# Install FastAPI dependencies\n!pip install -q fastapi uvicorn pyngrok nest-asyncio python-multipart aiofiles\n\n# Install PyTorch with CUDA support (make sure it's compatible)\n!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n\n# Install Gaussian Splatting submodules - order matters!\nprint(\"Installing Gaussian Splatting submodules...\")\n!pip install -q submodules/diff-gaussian-rasterization\n!pip install -q submodules/simple-knn\n\nprint(\"✓ All dependencies installed\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport sys\nimport shutil\nimport asyncio\nimport nest_asyncio\nimport subprocess\nimport cv2\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime\nfrom contextlib import asynccontextmanager\nfrom typing import List, Optional\n\nfrom fastapi import FastAPI, UploadFile, File, HTTPException, Header, Form\nfrom fastapi.responses import JSONResponse\nimport uvicorn\nfrom pyngrok import ngrok\nfrom google.colab import drive, userdata\n\n# Add gaussian-splatting to path\nsys.path.append('/content/gaussian-splatting')\n\n# Set environment for headless operation\nos.environ['PYOPENGL_PLATFORM'] = 'egl'\nos.environ['QT_QPA_PLATFORM'] = 'offscreen'\n\n# Add COLMAP to PATH\nos.environ['PATH'] = '/usr/bin:/usr/local/bin:' + os.environ.get('PATH', '')\n\n# Enable nested event loops\nnest_asyncio.apply()"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Configuration\n# Get secrets from Colab userdata\ntry:\n    NGROK_AUTHTOKEN = userdata.get('NGROK_AUTHTOKEN')\n    API_KEY = userdata.get('API_KEY')\nexcept Exception as e:\n    print(\"⚠️  Warning: Could not load secrets from Colab userdata\")\n    print(\"Please set NGROK_AUTHTOKEN and API_KEY in Colab secrets\")\n    print(\"Settings → Secrets → Add new secret\")\n    NGROK_AUTHTOKEN = None\n    API_KEY = None\n\nUPLOAD_DIR = Path(\"/content/uploads\")\nDATASET_DIR = Path(\"/content/datasets\")\nOUTPUT_DIR = Path(\"/content/drive/MyDrive/gaussian_splatting_outputs\")\n\n# Create directories\nUPLOAD_DIR.mkdir(exist_ok=True)\nDATASET_DIR.mkdir(exist_ok=True)\n\n# Set ngrok auth token\nif NGROK_AUTHTOKEN:\n    ngrok.set_auth_token(NGROK_AUTHTOKEN)\nelse:\n    raise ValueError(\"NGROK_AUTHTOKEN not found in Colab secrets\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 4️⃣ Processing Functions",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "def extract_frames_from_video(video_path: Path, output_dir: Path, fps: int = 2) -> List[Path]:\n    \"\"\"Extract frames from video at specified FPS\"\"\"\n    output_dir.mkdir(exist_ok=True)\n    \n    cap = cv2.VideoCapture(str(video_path))\n    video_fps = cap.get(cv2.CAP_PROP_FPS)\n    frame_interval = int(video_fps / fps)\n    \n    frame_paths = []\n    frame_count = 0\n    saved_count = 0\n    \n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n            \n        if frame_count % frame_interval == 0:\n            frame_path = output_dir / f\"frame_{saved_count:04d}.jpg\"\n            cv2.imwrite(str(frame_path), frame)\n            frame_paths.append(frame_path)\n            saved_count += 1\n            \n        frame_count += 1\n    \n    cap.release()\n    print(f\"Extracted {saved_count} frames from video\")\n    return frame_paths\n\n\ndef prepare_dataset_from_images(image_dir: Path, dataset_name: str) -> Path:\n    \"\"\"Prepare dataset structure for Gaussian Splatting\"\"\"\n    dataset_path = DATASET_DIR / dataset_name\n    dataset_path.mkdir(exist_ok=True)\n    \n    # Create input directory for images\n    input_dir = dataset_path / \"input\"\n    input_dir.mkdir(exist_ok=True)\n    \n    # Copy images to input directory\n    image_count = 0\n    for img_path in list(image_dir.glob(\"*.jpg\")) + list(image_dir.glob(\"*.png\")):\n        shutil.copy(img_path, input_dir)\n        image_count += 1\n    \n    print(f\"Copied {image_count} images to dataset\")\n    return dataset_path\n\n\ndef run_colmap_convert(dataset_path: Path) -> bool:\n    \"\"\"Run COLMAP using the convert.py script (with camera model fix)\"\"\"\n    print(\"\\nRunning COLMAP via convert.py...\")\n    \n    # Run convert script\n    cmd = [\n        \"python\", \"/content/gaussian-splatting/convert.py\",\n        \"-s\", str(dataset_path)\n    ]\n    \n    print(f\"Command: {' '.join(cmd)}\")\n    \n    # Set environment for headless operation - fix the DISPLAY issue\n    env = os.environ.copy()\n    env['QT_QPA_PLATFORM'] = 'offscreen'\n    \n    # Fix DISPLAY environment variable - ensure it's a string\n    if 'display' in globals():\n        env['DISPLAY'] = f\":{display.display}\"\n    else:\n        env['DISPLAY'] = ':0'\n    \n    result = subprocess.run(cmd, capture_output=True, text=True, env=env)\n    \n    print(f\"Return code: {result.returncode}\")\n    if result.stdout:\n        print(f\"STDOUT: {result.stdout}\")\n    if result.stderr:\n        print(f\"STDERR: {result.stderr}\")\n    \n    # Check if sparse reconstruction was created\n    sparse_dir = dataset_path / \"sparse\"\n    if sparse_dir.exists():\n        sparse_subdirs = [d for d in sparse_dir.iterdir() if d.is_dir() and d.name.isdigit()]\n        if sparse_subdirs:\n            print(f\"✓ COLMAP created sparse reconstruction in: {sparse_subdirs}\")\n            \n            # Check for camera model issues and fix if needed\n            for sparse_subdir in sparse_subdirs:\n                cameras_txt = sparse_subdir / \"cameras.txt\"\n                if cameras_txt.exists():\n                    fix_camera_model(cameras_txt)\n            \n            return True\n    \n    print(\"❌ COLMAP failed or no sparse reconstruction created\")\n    return False\n\n\ndef fix_camera_model(cameras_txt_path: Path):\n    \"\"\"Fix camera model to SIMPLE_PINHOLE if needed\"\"\"\n    print(f\"Checking camera model in {cameras_txt_path}\")\n    \n    try:\n        with open(cameras_txt_path, 'r') as f:\n            content = f.read()\n        \n        # If using OPENCV model, change to SIMPLE_PINHOLE\n        if \"OPENCV\" in content:\n            print(\"⚠️ Found OPENCV camera model, changing to SIMPLE_PINHOLE\")\n            \n            lines = content.split('\\n')\n            new_lines = []\n            \n            for line in lines:\n                if line.startswith('#') or not line.strip():\n                    new_lines.append(line)\n                    continue\n                \n                parts = line.split()\n                if len(parts) >= 5 and parts[1] == \"OPENCV\":\n                    # Change OPENCV to SIMPLE_PINHOLE and adjust parameters\n                    camera_id = parts[0]\n                    width = parts[2]\n                    height = parts[3]\n                    # Use average of fx, fy for SIMPLE_PINHOLE\n                    fx = float(parts[4])\n                    fy = float(parts[5]) if len(parts) > 5 else fx\n                    cx = float(parts[6]) if len(parts) > 6 else float(width) / 2\n                    cy = float(parts[7]) if len(parts) > 7 else float(height) / 2\n                    \n                    focal = (fx + fy) / 2\n                    new_line = f\"{camera_id} SIMPLE_PINHOLE {width} {height} {focal} {cx} {cy}\"\n                    new_lines.append(new_line)\n                    print(f\"  Changed: {line}\")\n                    print(f\"  To: {new_line}\")\n                else:\n                    new_lines.append(line)\n            \n            # Write back the modified content\n            with open(cameras_txt_path, 'w') as f:\n                f.write('\\n'.join(new_lines))\n            \n            print(\"✓ Camera model fixed\")\n    \n    except Exception as e:\n        print(f\"Warning: Could not fix camera model: {e}\")\n\n\nasync def run_colmap(dataset_path: Path):\n    \"\"\"Run COLMAP for structure from motion\"\"\"\n    print(\"\\n\" + \"=\"*60)\n    print(\"Running COLMAP reconstruction...\")\n    print(\"=\"*60)\n    \n    # Try running COLMAP convert\n    success = run_colmap_convert(dataset_path)\n    \n    if not success:\n        raise Exception(\"COLMAP preprocessing failed\")\n    \n    print(\"\\n✅ COLMAP completed successfully!\")\n\n\nasync def train_gaussian_splatting(dataset_path: Path, iterations: int = 7000) -> Path:\n    \"\"\"Train Gaussian Splatting model\"\"\"\n    print(f\"\\n\" + \"=\"*60)\n    print(f\"Training Gaussian Splatting for {iterations} iterations...\")\n    print(\"=\"*60)\n    \n    output_path = dataset_path / \"output\"\n    \n    # Check CUDA before training\n    import torch\n    if not torch.cuda.is_available():\n        raise Exception(\"CUDA not available for training\")\n    \n    print(f\"✓ CUDA available: {torch.cuda.get_device_name(0)}\")\n    \n    # Build training command\n    cmd = [\n        \"python\", \"/content/gaussian-splatting/train.py\",\n        \"-s\", str(dataset_path),\n        \"-m\", str(output_path),\n        \"--iterations\", str(iterations),\n        \"--save_iterations\", str(iterations),\n        \"--test_iterations\", str(iterations),\n        \"--quiet\"\n    ]\n    \n    print(f\"Running: {' '.join(cmd[:6])}...\")\n    \n    # Run training\n    env = os.environ.copy()\n    process = subprocess.run(cmd, capture_output=True, text=True, env=env)\n    \n    print(f\"Training return code: {process.returncode}\")\n    \n    if process.returncode != 0:\n        print(f\"Training STDERR: {process.stderr}\")\n        raise Exception(f\"Training failed: {process.stderr}\")\n    \n    # Check for output PLY file\n    ply_path = output_path / \"point_cloud\" / f\"iteration_{iterations}\" / \"point_cloud.ply\"\n    \n    if not ply_path.exists():\n        # List what was actually created\n        point_cloud_dir = output_path / \"point_cloud\"\n        if point_cloud_dir.exists():\n            available = [d.name for d in point_cloud_dir.iterdir() if d.is_dir()]\n            print(f\"Available iterations: {available}\")\n            \n            # Try to find any PLY file\n            for d in point_cloud_dir.iterdir():\n                if d.is_dir():\n                    ply_candidate = d / \"point_cloud.ply\"\n                    if ply_candidate.exists():\n                        print(f\"Found PLY at: {ply_candidate}\")\n                        return ply_candidate\n        \n        raise Exception(f\"No PLY file found. Expected: {ply_path}\")\n    \n    print(f\"✅ Training successful! PLY created: {ply_path}\")\n    return ply_path"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5️⃣ FastAPI Application"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    print(\"Starting 3D Gaussian Splatting API...\")\n    yield\n    print(\"Shutting down...\")\n\napp = FastAPI(\n    title=\"3D Gaussian Splatting API\",\n    description=\"Convert images/videos to 3D Gaussian Splatting models\",\n    version=\"1.0.0\",\n    lifespan=lifespan\n)\n\n\ndef verify_api_key(api_key: str = Header(None)):\n    if api_key != API_KEY:\n        raise HTTPException(status_code=401, detail=\"Invalid API key\")\n    return api_key\n\n\n@app.get(\"/\")\nasync def root():\n    return {\n        \"status\": \"online\",\n        \"message\": \"3D Gaussian Splatting API is running\",\n        \"endpoints\": [\"/\", \"/process\"],\n        \"gpu\": \"T4 (16GB VRAM)\"\n    }\n\n\n@app.post(\"/process\")\nasync def process_gaussian_splatting(\n    files: List[UploadFile] = File(...),\n    iterations: Optional[int] = Form(1000),  # Reduced default for testing\n    extract_fps: Optional[int] = Form(2),\n    api_key: str = Header(None)\n):\n    \"\"\"Process images/video to create 3D Gaussian Splatting model\"\"\"\n    \n    verify_api_key(api_key)\n    \n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    job_name = f\"gs_{timestamp}\"\n    job_dir = UPLOAD_DIR / job_name\n    job_dir.mkdir(exist_ok=True)\n    \n    try:\n        # Process uploaded files\n        image_dir = job_dir / \"images\"\n        image_dir.mkdir(exist_ok=True)\n        \n        for file in files:\n            file_path = job_dir / file.filename\n            \n            # Save uploaded file\n            with open(file_path, \"wb\") as f:\n                content = await file.read()\n                f.write(content)\n            \n            # Check if video or image\n            if file.filename.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n                # Extract frames from video\n                extract_frames_from_video(file_path, image_dir, fps=extract_fps)\n            else:\n                # Copy image to image directory\n                shutil.copy(file_path, image_dir)\n        \n        # Check if we have enough images\n        image_count = len(list(image_dir.glob(\"*\")))\n        if image_count < 3:\n            raise HTTPException(\n                status_code=400,\n                detail=f\"Need at least 3 images, got {image_count}\"\n            )\n        \n        # For optimal results, warn if too few images\n        if image_count < 10:\n            print(f\"Warning: Only {image_count} images. For better results, use 10+ images with good overlap.\")\n        \n        print(f\"Processing {image_count} images...\")\n        \n        # Prepare dataset structure\n        dataset_path = prepare_dataset_from_images(image_dir, job_name)\n        \n        # Run COLMAP reconstruction\n        await run_colmap(dataset_path)\n        \n        # Train Gaussian Splatting model\n        ply_path = await train_gaussian_splatting(dataset_path, iterations)\n        \n        # Copy results to Google Drive\n        output_filename = f\"{job_name}_gaussian_splatting.ply\"\n        drive_path = OUTPUT_DIR / output_filename\n        shutil.copy(ply_path, drive_path)\n        \n        # Also save the entire output directory as zip (optional, might be large)\n        output_zip = f\"{job_name}_full_output\"\n        shutil.make_archive(\n            str(OUTPUT_DIR / output_zip),\n            'zip',\n            dataset_path / \"output\"\n        )\n        \n        return JSONResponse({\n            \"status\": \"success\",\n            \"job_id\": job_name,\n            \"model_file\": output_filename,\n            \"download_path\": f\"/content/drive/MyDrive/gaussian_splatting_outputs/{output_filename}\",\n            \"full_output_zip\": f\"{output_zip}.zip\",\n            \"images_processed\": image_count,\n            \"iterations\": iterations,\n            \"completed_at\": datetime.now().isoformat()\n        })\n        \n    except Exception as e:\n        # Log the full error for debugging\n        import traceback\n        print(f\"Error processing job {job_name}:\")\n        print(traceback.format_exc())\n        \n        # Clean up on error\n        if job_dir.exists():\n            shutil.rmtree(job_dir, ignore_errors=True)\n        \n        # Return detailed error for debugging\n        raise HTTPException(\n            status_code=500, \n            detail=f\"Processing failed: {str(e)}\"\n        )\n    \n    finally:\n        # Clean up temporary files (keep dataset for debugging if needed)\n        if job_dir.exists():\n            shutil.rmtree(job_dir, ignore_errors=True)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6️⃣ Launch Server with ngrok"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Start the server\nimport threading\n\ndef run_server():\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n\n# Start server thread\nserver_thread = threading.Thread(target=run_server, daemon=True)\nserver_thread.start()\n\n# Wait for server to start\nimport time\ntime.sleep(3)\n\n# Create ngrok tunnel\ntunnel = ngrok.connect(8000)\npublic_url = tunnel.public_url\n\nprint(\"\\n\" + \"=\"*60)\nprint(f\"🚀 3D Gaussian Splatting API is live at: {public_url}\")\nprint(\"=\"*60)\nprint(f\"\\nTest with:\")\nprint(f\"export PUBLIC_URL='{public_url}'\")\nprint(f\"export API_KEY='{API_KEY}'\")\nprint(f\"\\nFor multiple images:\")\nprint(f'curl -X POST $PUBLIC_URL/process -H \"Api-Key: $API_KEY\" -F \"files=@img1.jpg\" -F \"files=@img2.jpg\" -F \"files=@img3.jpg\"')\nprint(f\"\\nFor video:\")\nprint(f'curl -X POST $PUBLIC_URL/process -H \"Api-Key: $API_KEY\" -F \"files=@video.mp4\" -F \"extract_fps=2\"')\nprint(\"\\n\" + \"=\"*60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep alive\n",
    "print(\"\\n⏰ Server is running. Keep this cell executing to maintain the connection.\")\n",
    "print(\"⚠️  Processing may take 10-30 minutes depending on image count and settings.\")\n",
    "print(\"Press 'Stop' to shutdown the server.\\n\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(60)\n",
    "        print(f\"[{datetime.now().strftime('%H:%M:%S')}] Server alive at: {public_url}\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nShutting down server...\")\n",
    "    ngrok.disconnect(public_url)\n",
    "    ngrok.kill()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}